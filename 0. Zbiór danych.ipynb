{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb62ff54",
   "metadata": {},
   "source": [
    "Przed oddaniem zadania upewnij się, że wszystko działa poprawnie.\n",
    "**Uruchom ponownie kernel** (z paska menu: Kernel$\\rightarrow$Restart) a następnie\n",
    "**wykonaj wszystkie komórki** (z paska menu: Cell$\\rightarrow$Run All).\n",
    "\n",
    "Upewnij się, że wypełniłeś wszystkie pola `TU WPISZ KOD` lub `TU WPISZ ODPOWIEDŹ`, oraz\n",
    "że podałeś swoje imię i nazwisko poniżej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40079ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab05285",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afebc7d",
   "metadata": {},
   "source": [
    "# 0. Zbiór danych"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960c6389",
   "metadata": {},
   "source": [
    "W ramach obecnego laboratorium będziemy badać metody wielomodalnego uczenia reprezentacji. W tym celu wykorzystamy zbiór danych `Memotion Dataset 7k`. Zbiór składa się z około 7,000 memów, a każdy z nich jest oceniony pod względem: humorystyki (`humour`), sarkazmu (`sarcasm`), ofensywności (`offensive`), czy jest motywacyjny (`motivational`) oraz ogólnego wydźwięku (`sentiment`). W celu przyspieszenia uczenia modeli rozważanych w trakcie tego laboratorium wybierzemy mniejszy podzbiór memów.\n",
    "\n",
    "\n",
    "## 0.0. Pobranie i przygotowanie zbioru\n",
    "a) Wykorzystując [link do Kaggle](https://www.kaggle.com/williamscott701/memotion-dataset-7k), należy pobrać zbiór danych i rozpakować go do katalogu `data/memotion/` (tak aby w tym katalogu znajdowały się: katalog `images/` oraz plik `labels.csv`)\n",
    "\n",
    "b) Po przygotowaniu środowiska Pythonowego, należy wygenerować zbiór danych uruchamiając komendę:\n",
    "```bash\n",
    "$ python3 scripts/prepare_memotion.py\n",
    "```\n",
    "Skrypt ten wczyta oznaczenia danych (`labels.csv`) i dla każdego mema:\n",
    "- wczyta obrazek i zamieni go na format, który będzie łatwy do użycia w celach wizualizacyjnych\n",
    "- uruchomi model osadzania obrazków na każdym z nich (tutaj: **ResNet50**)\n",
    "- uruchomi model osadzania tekstu na każdy podpisie mema (tutaj: **all-MiniLM-L6-v2** z biblioteki `sentence-transformers`)\n",
    "\n",
    "Następnie przekształcone powyższe atrybuty zostaną zapisane w pliku `data/processed.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44faf0f1-7342-40bc-8794-a99c2a74cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run command below if you prefer to run the script from this notebook\n",
    "# !python3 scripts/prepare_memotion.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe9abf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f23df3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data/processed.pkl\")\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2018e260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from src.visualization import make_interactive_scatter_plot\n",
    "\n",
    "img_emb = torch.stack(df[\"img_emb\"].values.tolist())\n",
    "\n",
    "make_interactive_scatter_plot(\n",
    "    title=\"Raw image embeddings\",\n",
    "    z_2d=PCA(n_components=2).fit_transform(img_emb),\n",
    "    df=df,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade223c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualization import visualize_most_similar\n",
    "\n",
    "\n",
    "_ = visualize_most_similar(\n",
    "    title=\"Most similar by image embedding\",\n",
    "    anchor_index=339,\n",
    "    z=img_emb,\n",
    "    df=df,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e45f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_emb = torch.stack(df[\"text_emb\"].values.tolist())\n",
    "\n",
    "make_interactive_scatter_plot(\n",
    "    title=\"Raw text embeddings\",\n",
    "    z_2d=PCA(n_components=2).fit_transform(text_emb),\n",
    "    df=df,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea12471",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = visualize_most_similar(\n",
    "    title=\"Most similar by text embedding\",\n",
    "    anchor_index=339,\n",
    "    z=text_emb,\n",
    "    df=df,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
